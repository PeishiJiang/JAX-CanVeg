09:50:28,415 root INFO Start training JAX-CanVeg with the configuration file configs.json under test-model
09:50:28,421 root INFO Loading training forcings and fluxes...
09:50:28,674 jax._src.xla_bridge INFO Unable to initialize backend 'cuda': 
09:50:28,674 jax._src.xla_bridge INFO Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
09:50:28,674 jax._src.xla_bridge INFO Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: '/opt/homebrew/opt/llvm/lib/libtpu.so' (no such file), 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/Users/jian449/anaconda3/envs/jax-canoak/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/jian449/anaconda3/envs/jax-canoak/lib/libtpu.so' (no such file), '/Users/jian449/anaconda3/envs/jax-canoak/bin/../lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)
09:50:28,838 root INFO Loading test forcings and fluxes if any...
09:50:28,952 root INFO number of lagrangian particles is not found in configuration of model and return 1000000.
09:50:28,952 root INFO Loading the model setup and parameters ...
09:50:29,670 root INFO Loading the disperion matrix ...
09:50:29,670 root INFO Reading dispersion matrix from ../../../data/dij/Dij_US-Whs.csv
09:50:29,683 root INFO Getting model type CanvegIFT ...
09:50:29,684 root INFO Getting output function that gives canopy latent heat fluxes and net ecosystem exchange ...
09:50:29,756 root INFO Converting the obs and met to batched dataset ...
09:50:29,850 root INFO Getting the filtered model spec for the tunable parameters ...
09:50:29,851 root INFO Getting the loss function ...
09:50:29,857 root INFO Getting the optimizer and training epochs ...
09:52:23,454 root INFO The training loss of step 0: 2.9423119103573954; the test loss of step 0: 1.7795309992552435.
09:54:02,637 root INFO The training loss of step 1: 2.8010429173332394; the test loss of step 1: 1.467692839073243.
09:55:15,210 root INFO The training loss of step 2: 2.330777323988945; the test loss of step 2: 1.2250239196620698.
09:56:29,682 root INFO The training loss of step 3: 1.9349266593136736; the test loss of step 3: 1.037661357934986.
09:57:43,871 root INFO The training loss of step 4: 1.6004647897523068; the test loss of step 4: 0.9051762584328008.
09:57:43,871 root INFO Saving the loss values ...
09:57:43,905 root INFO Saving the trained model ...
