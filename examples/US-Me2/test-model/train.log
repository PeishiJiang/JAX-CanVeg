09:57:38,113 root INFO Start training JAX-CanVeg with the configuration file configs.json under test-model
09:57:38,124 root INFO Loading training forcings and fluxes...
09:57:38,215 jax._src.xla_bridge INFO Unable to initialize backend 'cuda': 
09:57:38,215 jax._src.xla_bridge INFO Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
09:57:38,216 jax._src.xla_bridge INFO Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: '/opt/homebrew/opt/llvm/lib/libtpu.so' (no such file), 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/Users/jian449/anaconda3/envs/jax-canoak/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/jian449/anaconda3/envs/jax-canoak/lib/libtpu.so' (no such file), '/Users/jian449/anaconda3/envs/jax-canoak/bin/../lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)
09:57:38,390 root INFO Loading test forcings and fluxes if any...
09:57:38,537 root INFO number of lagrangian particles is not found in configuration of model and return 1000000.
09:57:38,537 root INFO Loading the model setup and parameters ...
09:57:39,445 root INFO Loading the disperion matrix ...
09:57:39,445 root INFO Reading dispersion matrix from ../../../data/dij/Dij_US-Me2.csv
09:57:39,464 root INFO Getting model type CanvegIFT ...
09:57:39,466 root INFO Getting output function that gives canopy latent heat fluxes and net ecosystem exchange ...
09:57:39,536 root INFO Converting the obs and met to batched dataset ...
09:57:39,637 root INFO Getting the filtered model spec for the tunable parameters ...
09:57:39,639 root INFO Getting the loss function ...
09:57:39,644 root INFO Getting the optimizer and training epochs ...
10:00:56,219 root INFO The training loss of step 0: 2.6599191273108684; the test loss of step 0: 1.1754567106574305.
10:02:46,357 root INFO The training loss of step 1: 2.2587428388044257; the test loss of step 1: 0.892571561540131.
10:04:17,261 root INFO The training loss of step 2: 1.766035230702043; the test loss of step 2: 0.666091510700542.
10:05:42,893 root INFO The training loss of step 3: 1.3399156245644348; the test loss of step 3: 0.49158008527886465.
10:07:08,740 root INFO The training loss of step 4: 0.9656543635028983; the test loss of step 4: 0.3877599521522794.
10:07:08,740 root INFO Saving the loss values ...
10:07:08,778 root INFO Saving the trained model ...
