{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following codes are adopted from an IFT tutorial over here: http://implicit-layers-tutorial.org/implicit_functions/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_solver(f, z_init):\n",
    "    z_prev, z = z_init, f(z_init)\n",
    "    while jnp.linalg.norm(z_prev - z) > 1e-5:\n",
    "        z_prev, z = z, f(z)\n",
    "    return z\n",
    "\n",
    "\n",
    "def newton_solver(f, z_init):\n",
    "    f_root = lambda z: f(z) - z\n",
    "    g = lambda z: z - jnp.linalg.solve(jax.jacobian(f_root)(z), f_root(z))\n",
    "    return fwd_solver(g, z_init)\n",
    "\n",
    "\n",
    "def anderson_solver(f, z_init, m=5, lam=1e-4, max_iter=50, tol=1e-5, beta=1.0):\n",
    "    x0 = z_init\n",
    "    x1 = f(x0)\n",
    "    x2 = f(x1)\n",
    "    X = jnp.concatenate([jnp.stack([x0, x1]), jnp.zeros((m - 2, *jnp.shape(x0)))])\n",
    "    F = jnp.concatenate([jnp.stack([x1, x2]), jnp.zeros((m - 2, *jnp.shape(x0)))])\n",
    "\n",
    "    res = []\n",
    "    for k in range(2, max_iter):\n",
    "        n = min(k, m)\n",
    "        G = F[:n] - X[:n]\n",
    "        GTG = jnp.tensordot(G, G, [list(range(1, G.ndim))] * 2)\n",
    "        H = jnp.block(\n",
    "            [[jnp.zeros((1, 1)), jnp.ones((1, n))], [jnp.ones((n, 1)), GTG]]\n",
    "        ) + lam * jnp.eye(n + 1)\n",
    "        alpha = jnp.linalg.solve(H, jnp.zeros(n + 1).at[0].set(1))[1:]\n",
    "\n",
    "        xk = beta * jnp.dot(alpha, F[:n]) + (1 - beta) * jnp.dot(alpha, X[:n])\n",
    "        X = X.at[k % m].set(xk)\n",
    "        F = F.at[k % m].set(f(xk))\n",
    "\n",
    "        res = jnp.linalg.norm(F[k % m] - X[k % m]) / (1e-5 + jnp.linalg.norm(F[k % m]))\n",
    "        if res < tol:\n",
    "            break\n",
    "    return xk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed point function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_point_layer(solver, f, params, x):\n",
    "    z_star = solver(lambda z: f(params, x, z), z_init=jnp.zeros_like(x))\n",
    "    return z_star\n",
    "\n",
    "\n",
    "f = lambda W, x, z: jnp.tanh(jnp.dot(W, z) + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 10\n",
    "W = random.normal(random.PRNGKey(0), (ndim, ndim)) / jnp.sqrt(ndim)\n",
    "x = random.normal(random.PRNGKey(1), (ndim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00649598 -0.7015958  -0.984715   -0.04196562 -0.61522174 -0.4818382\n",
      "  0.5783123   0.9556705  -0.08373147  0.8447805 ]\n"
     ]
    }
   ],
   "source": [
    "z_star = fixed_point_layer(fwd_solver, f, W, x)\n",
    "print(z_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00649405 -0.701595   -0.98471504 -0.04196506 -0.6152211  -0.4818385\n",
      "  0.57831246  0.9556705  -0.08372928  0.8447799 ]\n"
     ]
    }
   ],
   "source": [
    "z_star = fixed_point_layer(newton_solver, f, W, x)\n",
    "print(z_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive automatic differentiation through iterative solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0075667  -0.8125902  -1.1404794  -0.04861286 -0.71255237 -0.5580556\n",
      "  0.66978824  1.1068414  -0.09702272  0.97842246]\n"
     ]
    }
   ],
   "source": [
    "g = jax.grad(lambda W: fixed_point_layer(fwd_solver, f, W, x).sum())(W)\n",
    "print(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00752129 -0.81257427 -1.1404787  -0.04860315 -0.7125375  -0.5580563\n",
      "  0.66979074  1.1068397  -0.09697369  0.97840846]\n"
     ]
    }
   ],
   "source": [
    "g = jax.grad(lambda W: fixed_point_layer(newton_solver, f, W, x).sum())(W)\n",
    "print(g[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VJP and JVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6371896\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return jnp.sin(x) * x**2\n",
    "\n",
    "\n",
    "x = 2.0\n",
    "y = f(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6371896\n",
      "1.9726022\n"
     ]
    }
   ],
   "source": [
    "w = 1.0\n",
    "y, f_vjp = jax.vjp(f, x)\n",
    "(lmbda,) = f_vjp(w)\n",
    "print(y)\n",
    "print(lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59582317\n",
      "1.1477209\n"
     ]
    }
   ],
   "source": [
    "h = jnp.sin\n",
    "g = lambda x: x**3\n",
    "\n",
    "f = lambda x: g(h(x))\n",
    "z, delta_z = jax.jvp(f, (1.0,), (1.0,))\n",
    "print(z)\n",
    "print(delta_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59582317\n",
      "1.1477209\n"
     ]
    }
   ],
   "source": [
    "def f_jvp(x, delta_x):\n",
    "    y, delta_y = jax.jvp(h, (x,), (delta_x,))\n",
    "    z, delta_z = jax.jvp(g, (y,), (delta_y,))\n",
    "    return z, delta_z\n",
    "\n",
    "\n",
    "z, delta_z = f_jvp(1.0, 1.0)\n",
    "print(z)\n",
    "print(delta_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59582317\n",
      "1.1477209\n"
     ]
    }
   ],
   "source": [
    "def f_vjp(x, w):\n",
    "    y, h_vjp = jax.vjp(h, x)\n",
    "    z, g_vjp = jax.vjp(g, y)\n",
    "    (delta_y,) = h_vjp(w)\n",
    "    (delta_z,) = g_vjp(delta_y)\n",
    "    return z, delta_z\n",
    "\n",
    "\n",
    "z, delta_z = f_vjp(1.0, 1.0)\n",
    "print(z)\n",
    "print(delta_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit function theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.custom_vjp, nondiff_argnums=(0, 1))\n",
    "def fixed_point_layer(solver, f, params, x):\n",
    "    z_star = solver(lambda z: f(params, x, z), z_init=jnp.zeros_like(x))\n",
    "    return z_star\n",
    "\n",
    "\n",
    "def fixed_point_layer_fwd(solver, f, params, x):\n",
    "    z_star = fixed_point_layer(solver, f, params, x)\n",
    "    return z_star, (params, x, z_star)\n",
    "\n",
    "\n",
    "def fixed_point_layer_bwd(solver, f, res, z_star_bar):\n",
    "    params, x, z_star = res\n",
    "    _, vjp_a = jax.vjp(lambda params, x: f(params, x, z_star), params, x)\n",
    "    _, vjp_z = jax.vjp(lambda z: f(params, x, z), z_star)\n",
    "    return vjp_a(\n",
    "        solver(lambda u: vjp_z(u)[0] + z_star_bar, z_init=jnp.zeros_like(z_star))\n",
    "    )\n",
    "\n",
    "\n",
    "fixed_point_layer.defvjp(fixed_point_layer_fwd, fixed_point_layer_bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall we had these definitions for f, W, and x\n",
    "ndim = 10\n",
    "W = random.normal(random.PRNGKey(0), (ndim, ndim)) / jnp.sqrt(ndim)\n",
    "f = lambda W, x, z: jnp.tanh(jnp.dot(W, z) + x)\n",
    "x = random.normal(random.PRNGKey(1), (ndim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.00649598, -0.7015958 , -0.984715  , -0.04196562, -0.61522174,\n",
       "       -0.4818382 ,  0.5783123 ,  0.9556705 , -0.08373147,  0.8447805 ],      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_point_layer(fwd_solver, f, W, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0075235  -0.812573   -1.1404755  -0.04860367 -0.7125365  -0.55805457\n",
      "  0.6697887   1.1068368  -0.09697597  0.9784065 ]\n"
     ]
    }
   ],
   "source": [
    "g = jax.grad(lambda W: fixed_point_layer(fwd_solver, f, W, x).sum())(W)\n",
    "print(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-watershed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
