10:00:59,801 root INFO Start training JAX-CanVeg with the configuration file configs.json under test-model
10:00:59,803 root INFO Loading training forcings and fluxes...
10:00:59,880 jax._src.xla_bridge INFO Unable to initialize backend 'cuda': 
10:00:59,880 jax._src.xla_bridge INFO Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
10:00:59,881 jax._src.xla_bridge INFO Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: '/opt/homebrew/opt/llvm/lib/libtpu.so' (no such file), 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/Users/jian449/anaconda3/envs/jax-canoak/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/jian449/anaconda3/envs/jax-canoak/lib/libtpu.so' (no such file), '/Users/jian449/anaconda3/envs/jax-canoak/bin/../lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)
10:00:59,977 root INFO Loading test forcings and fluxes if any...
10:01:00,57 root INFO number of lagrangian particles is not found in configuration of model and return 1000000.
10:01:00,57 root INFO Loading the model setup and parameters ...
10:01:00,725 root INFO Loading the disperion matrix ...
10:01:00,725 root INFO Reading dispersion matrix from ../../../data/dij/Dij_US-Hn1.csv
10:01:00,733 root INFO Getting model type CanvegIFT ...
10:01:00,735 root INFO Getting output function that gives canopy latent heat fluxes and net ecosystem exchange ...
10:01:00,787 root INFO Converting the obs and met to batched dataset ...
10:01:00,868 root INFO Getting the filtered model spec for the tunable parameters ...
10:01:00,869 root INFO Getting the loss function ...
10:01:00,874 root INFO Getting the optimizer and training epochs ...
10:02:05,622 root INFO The training loss of step 0: 20.45841599759706; the test loss of step 0: 23.534937337776135.
10:02:59,480 root INFO The training loss of step 1: 17.364225226579986; the test loss of step 1: 18.885817397646626.
10:03:28,874 root INFO The training loss of step 2: 13.887537326368903; the test loss of step 2: 14.503346951281115.
10:04:00,835 root INFO The training loss of step 3: 10.680083857207334; the test loss of step 3: 10.06447173588211.
10:04:30,972 root INFO The training loss of step 4: 7.553886772119421; the test loss of step 4: 5.60875097142946.
10:04:30,972 root INFO Saving the loss values ...
10:04:31,8 root INFO Saving the trained model ...
