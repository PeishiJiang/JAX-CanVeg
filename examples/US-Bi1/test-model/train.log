09:43:53,884 root INFO Start training JAX-CanVeg with the configuration file configs.json under test-model
09:43:53,887 root INFO Loading training forcings and fluxes...
09:43:54,15 jax._src.xla_bridge INFO Unable to initialize backend 'cuda': 
09:43:54,16 jax._src.xla_bridge INFO Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
09:43:54,16 jax._src.xla_bridge INFO Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: '/opt/homebrew/opt/llvm/lib/libtpu.so' (no such file), 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/Users/jian449/anaconda3/envs/jax-canoak/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/jian449/anaconda3/envs/jax-canoak/lib/libtpu.so' (no such file), '/Users/jian449/anaconda3/envs/jax-canoak/bin/../lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)
09:43:54,135 root INFO Loading test forcings and fluxes if any...
09:43:54,257 root INFO number of lagrangian particles is not found in configuration of model and return 1000000.
09:43:54,257 root INFO Loading the model setup and parameters ...
09:43:54,952 root INFO Loading the disperion matrix ...
09:43:54,953 root INFO Reading dispersion matrix from ../../../data/dij/Dij_US-Bi1.csv
09:43:54,963 root INFO Getting model type CanvegIFT ...
09:43:54,964 root INFO Getting output function that gives canopy latent heat fluxes and net ecosystem exchange ...
09:43:55,38 root INFO Converting the obs and met to batched dataset ...
09:43:55,124 root INFO Getting the filtered model spec for the tunable parameters ...
09:43:55,125 root INFO Getting the loss function ...
09:43:55,131 root INFO Getting the optimizer and training epochs ...
09:46:20,291 root INFO The training loss of step 0: 0.23430131889499767; the test loss of step 0: 0.1779928404590677.
09:48:24,185 root INFO The training loss of step 1: 0.2018138898455654; the test loss of step 1: 0.16225013942557304.
09:50:02,268 root INFO The training loss of step 2: 0.171420792770872; the test loss of step 2: 0.16905428998781988.
09:51:43,752 root INFO The training loss of step 3: 0.16403808080692758; the test loss of step 3: 0.18984585844626997.
09:53:26,719 root INFO The training loss of step 4: 0.17232113520305084; the test loss of step 4: 0.20490990017877847.
09:53:26,720 root INFO Saving the loss values ...
09:53:26,762 root INFO Saving the trained model ...
